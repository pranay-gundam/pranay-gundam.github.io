<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://pranay-gundam.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pranay-gundam.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-17T23:24:01+00:00</updated><id>https://pranay-gundam.github.io/feed.xml</id><title type="html">Pranay Gundam</title><entry><title type="html">spatial models update and stanning for github copilot</title><link href="https://pranay-gundam.github.io/blog/2024/github-copilot-fan-post/" rel="alternate" type="text/html" title="spatial models update and stanning for github copilot"/><published>2024-08-17T19:10:00+00:00</published><updated>2024-08-17T19:10:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/github-copilot-fan-post</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/github-copilot-fan-post/"><![CDATA[<p>I wanted to start off by saying that Github Co-Pilot is amazing. I‚Äôm not super sure about the specifics of what it trains on but it has to somehow look at my git tracked code and give suggestions based on my coding style which is just spectacular. Often times the most demoralizing part of doing a coding project is typing out tedious code that one knows how to write but just takes effort and unnessary mental energy (especially if there are some unintended bugs). Co-Pilot bypasses all of that with just one keystroke; more often than not the code that Co-Pilot writes is not buggy (especially if it‚Äôs something not particularly complicated). The greatest thing is that sure you can ask write out a detailed prompt in the chat window for AI to interpret and answer, but Co-Pilot also has an autocomplete feature where you can only write out the name of the function and it does the rest for you (sometimes it even knows what function you want to write next before you type out the name).</p> <p>Then also, before I get into the spatial stuff, one update on <a href="https://github.com/pranay-gundam/TidyTuesday">TidyTuesday</a>. The code is still a work in progress; I still need to get it to a state where I‚Äôm satisfied enough to not touch it for a while. That being said, it is currently functional. Meaning I can go on with my TidyTuesday blog series plans but there‚Äôs still a little to be done to make it fully automated and also include data from more than just Fred.</p> <p>With those two things out of the way, I want to talk a little about spatial econ. I‚Äôm not really sure what it is about spatial models that really captures me. If I were to guess, I know I have had somewhat of an interest in the movement of peoples and how they organize in the context of a city for a while since highschool and it was this interest that leaned me towards doing something spatial related for my senior thesis which has then kept me interested in the field.</p> <p>Before I learned a lot of macro, however, I used to think that there was something intrinsically different between the model written in the spatial literature and those in the general macro setting. This may be just from ignorance of not knowing the general questions that a macro model uses to motivate itself, but in my involvement in the spatial literature thus far I have realized that the inherent motivation is very similar: households making a selection from some choice set to maximize their utility given some budget constraints that introduce unique mechanics. There are few key components of a spatial general equilibrium models that I‚Äôve found are the key marked differences between the two:</p> <ul> <li>The choice set for households (also firms as well for models that include those) is expanded to choosing places to live (and work). Models can differ vastly in terms of when these choices are made or restrictions on how such a choice is made but the commuting costs of households and goods is what gives birth to the rich spatial dynamics that relate the model to reality.</li> <li>Location (blocks) have unique characteristics (which can be anything from natural landmarks to the vibes of a neighborhood) that are incorporated into the model in various ways <ul> <li>Household preferences for these characteristics</li> <li>local productivity shocks and spillover effects</li> </ul> </li> </ul> <p>These two differences are what drive the unique analysis that we can do with spatial models. For example, we can look at how the migration flows (either people moving their residence or working location) change in response to a local productivity shock, or we can see the extent of the effect that local spillovers have on the composition of households in a location. This may seem a bit abstract to those non-macroeconomics readers in terms of the mechanics of the math, so let‚Äôs dive into some more specifics.</p> <p>At its core, a structural macro model is built on connecting the optimization problems of various groups of different types of agents. For the toy model we are building now:</p> <ul> <li>There is a discount factor \(\beta \in (0,1)\) and capital depreciation rate \(\delta \in [0,1]\).</li> <li>Let there be \(N\) many location blocks in which households choose to live and work. Each location also has a living amenity rate \(A_i\) which factors into a household‚Äôs utility function.</li> <li>A household is an agent who lives forever and faces the main problem of choosing how much of a good to consume at each point in time \(c_t\), how much time to spend on leisure \(l_t\) instead of working, and which location blocks \(i\) and \(j\) to live and work in respectively (they have to pay a commuting fee \(d_{i,j}\) for every time period based on the chosen \(i\) and \(j\)). Households also have the ability to save from time period to time period and these savings affect (this very nebulous and confusing concept to those not in econ that we call) capital \(k_t\).</li> <li>There are no firms in this world; rather, households ‚Äúmake money‚Äù using a production function \(Z_{i_t}\cdot F(k_t, 1 - l_t)\) which uses some function \(F\) to relate how much a household produces based on how much capital they possess and how much time they spend working instead of as leisure time. The \(Z_{i_t}\) is a location-specific random process that all have different means and variances that the households are not sure about, so that one‚Äôs working location has an effect on how much they are able to produce: since the process is different for each location, each location has different shocks as well. <ul> <li>This is where I‚Äôm making the spatial model ‚Äúinteresting‚Äù. The model isn‚Äôt just incorporating the spatial component by making households choose where they want to live and work based on which is the best place to live in terms of the amenities and distance to work but also which has good future prospects for location productivity.</li> </ul> </li> </ul> <p>Specifically, the households solve the following optimization problem [\max_{c_t, l_t, i_t, j_t} \sum_{t=0}^\infty \beta^t u(c_t, l_t, A_{i_t}),] subject to constraints [c_t + d_{i_t, j_t} + s_t \leq Z_{i_t}\cdot F(k_t, 1 - l_t),\ k_{t+1} = \delta k_t + s_t.]</p> <p>It took me a bit of training to be able to do this, but from the problem statement above you can already paint a qualitative picture of the push and pull that affects the households. They want to choose a location to live in with high location amenities, but they also want it to be close to their work, and they also want to choose a place to work that they think has good prospects for its productivity that factors into the households‚Äô production function (their way of making money). They can also turn the levers of how they make money by saving money for the future to build up their capital. There‚Äôs a lot going on already without adding too much complexity; don‚Äôt get me started on how to solve and estimate these models.</p> <p>There are plenty more features we can build into this to make it more interesting or realistic, such as introducing firms, government agents, or some intrinsic heterogeneity between households; for example, some households can have low levels of education while others can have higher, which affects their respective production functions and may influence their migratory decisions. My NSF proposal will likely tinker with a couple of these ‚Äúbonus‚Äù features and study them in the context of government policy and their spatial implications.</p> <p>Of course, not even I would say that the model we built above is consistent with reality, and even if we were to relax a few assumptions, we would still be nowhere close. This brings me to a point of economic maturity that I‚Äôve come to learn over the past year. Very rarely in econ are people who are doing these structural models caught up with trying to replicate reality; it is more about exploring the relative effects of some channels on others that is what is interesting in monetary policy research. As always, my blog posts are very stream-of-consciousness and more so a personal outlet for me to espouse some thoughts, so I‚Äôm not sure how coherent any of the above is to an outside reader. If you want to know more or are confused (most people reading probably know me in real life, so texting is also good üòä).</p> <p>So to close off, the NSF application is coming along and will help me a lot with the <a href="https://github.com/pranay-gundam/spatial-sims">spatial sims</a> package that has been a work in progress for such a long time. As a recap and update on that, my plans for the package had started almost a year ago around this time but I soon postponed it after realizing how much more I had to learn to get to a position to understand how exactly I could accomplish my goals with the package. I‚Äôm not currently at a level of economic maturity where I can just sit down and write all the code myself in a month, but I definitely understand what is going on and I know a lot more than before (understanding <a href="https://github.com/FRBNY-DSGE/DSGE.jl">DSGE.jl</a>, <a href="https://github.com/FRBNY-DSGE/SMC.jl">SMC.jl</a>, and <a href="https://github.com/FRBNY-DSGE/ModelConstructors.jl">ModelConstructors.jl</a> has helped an incredible amount). I‚Äôll still probably need to find people to help me out with it, but the current plan is to get back into writing out the models for the package and coding it up once PhD applications are all submitted (sometime in the beginning of 2025).</p>]]></content><author><name></name></author><category term="econ-thoughts"/><category term="tidy-tuesday"/><summary type="html"><![CDATA[I wanted to start off by saying that Github Co-Pilot is amazing. I‚Äôm not super sure about the specifics of what it trains on but it has to somehow look at my git tracked code and give suggestions based on my coding style which is just spectacular. Often times the most demoralizing part of doing a coding project is typing out tedious code that one knows how to write but just takes effort and unnessary mental energy (especially if there are some unintended bugs). Co-Pilot bypasses all of that with just one keystroke; more often than not the code that Co-Pilot writes is not buggy (especially if it‚Äôs something not particularly complicated). The greatest thing is that sure you can ask write out a detailed prompt in the chat window for AI to interpret and answer, but Co-Pilot also has an autocomplete feature where you can only write out the name of the function and it does the rest for you (sometimes it even knows what function you want to write next before you type out the name).]]></summary></entry><entry><title type="html">summer of 2024</title><link href="https://pranay-gundam.github.io/blog/2024/" rel="alternate" type="text/html" title="summer of 2024"/><published>2024-08-10T17:28:00+00:00</published><updated>2024-08-10T17:28:00+00:00</updated><id>https://pranay-gundam.github.io/blog/</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/"><![CDATA[<p>The first thing I want to talk about is that I‚Äôve made pretty significant progress on the TidyTuesday front. Turns out that having a very clearly defined project that works with data and nice APIs really gets me motivated to make progress on it. There are always more features and capabilities to add with these sorts of things, but I‚Äôm pretty sure I‚Äôll be able to finish the baseline version that works with the Fred API by this weekend and get it up and running to be able to make my first renewed TidyTuesday post by next next Tuesday. Just as a reminder if you didn‚Äôt catch the last blog post, the idea is to renew the TidyTuesday series by running a random regression every day and reporting on one of the interesting ones each week; maybe there‚Äôs some cool interaction to discover (although very unlikely). I‚Äôm also using this as an opportunity to get some practice in writing code to compartmentalize and automatically generate chunks of reports in LaTeX where I only need to contribute to writing some qualitative color and everything else is already taken care of (something that‚Äôs a very helpful tool when working with products that are run repetitively with different data or small changes much like the work we do with forecasting on DSGE at the Fed).</p> <p>In other news, this summer is almost to an end. It has gone by both pretty quickly and gruelingly slow at times, but we are now entering quite the stressful era with PhD applications coming up soon. To be honest, I really don‚Äôt want to talk much about all the stressful stuff, so here are a few of the new restaurants and bakeries that I‚Äôve been to over the summer that I want to highlight (these are all places in New York):</p> <ul> <li>Dominique Ansel</li> <li>Little Flower Cafe</li> <li>Win Son Bakery (can‚Äôt believe it took me this long to go here)</li> <li>NONONO</li> <li>Obica Mozzarella Bar</li> <li>Cafe China</li> <li>Glaze Teriyaki</li> <li>Cha Pa‚Äôs Noodles and Grill</li> </ul> <p>I‚Äôm not going to talk much about any of these right now, but there is a favorites in NYC so far post that is coming up as well. Along those lines, here are some places that are still on the list and I will be hitting sometime soon:</p> <ul> <li>Lucali‚Äôs</li> <li>Steve‚Äôs Authentic Key Lime Pie</li> <li>Birdbox (really curious to see if this dethrones Rowdy Rooster as my favorite fried chicken place)</li> </ul> <p>Finally, as a preface for next week, I‚Äôll finally be talking about some of my NSF ideas and a really basic general setup for spatial general equilibrium models that is not necessarily what I‚Äôll be using for NSF but something that may make its way into the eventual spatial-sims package (along with some more ideas about the purpose of the package now that I have a better grasp on the literature).</p>]]></content><author><name></name></author><category term="personal-updates"/><category term="the-pittsburgh-pallate"/><category term="tidy-tuesday"/><summary type="html"><![CDATA[The first thing I want to talk about is that I‚Äôve made pretty significant progress on the TidyTuesday front. Turns out that having a very clearly defined project that works with data and nice APIs really gets me motivated to make progress on it. There are always more features and capabilities to add with these sorts of things, but I‚Äôm pretty sure I‚Äôll be able to finish the baseline version that works with the Fred API by this weekend and get it up and running to be able to make my first renewed TidyTuesday post by next next Tuesday. Just as a reminder if you didn‚Äôt catch the last blog post, the idea is to renew the TidyTuesday series by running a random regression every day and reporting on one of the interesting ones each week; maybe there‚Äôs some cool interaction to discover (although very unlikely). I‚Äôm also using this as an opportunity to get some practice in writing code to compartmentalize and automatically generate chunks of reports in LaTeX where I only need to contribute to writing some qualitative color and everything else is already taken care of (something that‚Äôs a very helpful tool when working with products that are run repetitively with different data or small changes much like the work we do with forecasting on DSGE at the Fed).]]></summary></entry><entry><title type="html">Hello on Github! (and refurbishing TidyTuesday)</title><link href="https://pranay-gundam.github.io/blog/2024/refurbishing-TidyTuesday/" rel="alternate" type="text/html" title="Hello on Github! (and refurbishing TidyTuesday)"/><published>2024-08-03T17:45:00+00:00</published><updated>2024-08-03T17:45:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/refurbishing-TidyTuesday</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/refurbishing-TidyTuesday/"><![CDATA[<p>I have not posted in quite a while and this is mostly because I have been migrating my old website to this new one (which is also thanks to another new friend)! There are still some formatting kinks I want to work out and I need to figure out how to add both a comments section and an email subscriber button, but this will be my website for a long while to come (I am, for the first time, actually quite satisfied with it except for some very minor formatting issues).</p> <p>We will be getting back into our regularly scheduled weekly posts now with a flavor towards stuff I‚Äôm learning or experiencing whilst working on NSF just to efficiently multitask (although that being said there are still a lot of post ideas I still have in store as well).</p> <p>One other thing that has been in the back of my mind for a long while is TidyTuesday; I basically only did one post and abandoned it right after that. I realized right after the first post back then that it was not worth the time commitment required to make a quality post week after week. As I‚Äôve been uploading all the blogs back onto the new website and looking at the poor state of TidyTuesday, I remembered a conversation I had with a friend and work team member. We have this running joke about whenever we encounter a roadblock, the solution is to just ‚Äúrun a regression‚Äù as the empirical economists do. One day, somehow the conversation diverged to this as well, and we were making jokes about running random regressions one random timeseries. This is what I think I will turn TidyTuesday into: a script that runs automatically every day that picks two random timeseries from the plethora of data APIs and runs a regression between the two. Then every week I pick one of the seven that I found interesting and talk a little bit more about the relationship between the two timeseries.</p> <p>There are of course more details and functionalities I can add into the code to do this (such as picking some controls) but for now the project idea is just to do the automation and generate a systematic report each day (and then automatically push it to github). Regardless, I cannot promise much progress on this for a while between NSF and grad apps but do expect this to show its face by the end of the year.</p>]]></content><author><name></name></author><category term="personal-updates"/><category term="tidy-tuesday"/><summary type="html"><![CDATA[I have not posted in quite a while and this is mostly because I have been migrating my old website to this new one (which is also thanks to another new friend)! There are still some formatting kinks I want to work out and I need to figure out how to add both a comments section and an email subscriber button, but this will be my website for a long while to come (I am, for the first time, actually quite satisfied with it except for some very minor formatting issues).]]></summary></entry><entry><title type="html">the game theory of mutually assured destruction</title><link href="https://pranay-gundam.github.io/blog/2024/the-game-theory-of-mutually-assured-destruction/" rel="alternate" type="text/html" title="the game theory of mutually assured destruction"/><published>2024-06-23T21:36:00+00:00</published><updated>2024-06-23T21:36:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/the-game-theory-of-mutually-assured-destruction</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/the-game-theory-of-mutually-assured-destruction/"><![CDATA[<p>I have been getting a lot of ideas/questions from the Remembrance of Earth‚Äôs Past series. One of the concepts that shows up towards the end of the second book, The Dark Forest, and is discussed in a lot more detail in the third book, Death‚Äôs End, is the deterrence through mutually assured destruction or MAD.</p> <p>One quick tangent: I searched up what exactly the definition of MAD entails and although the definition of the terminology itself should apply, the term itself in the context of what it was made for applies specifically to mutually assured destruction through nuclear weapons with a first strike against a nation with second strike capabilities. So I‚Äôm not super sure if MAD the best term to describe what was happening in Death‚Äôs End since it was only one side threatening the destruction of both parties, in the book they call it simply ‚ÄúDark Forest Deterrence‚Äù but for the sake of this post I‚Äôll continue to call it MAD just because it does have logical parallels to the origin of the term (and also MAD is fewer characters to type out each time)</p> <p>In the book, the way MAD was threatened was through an ‚Äúuniversal broadcast‚Äù that Earth could send out that included the located of the alien species‚Äô star system and since humankind‚Äôs system and Trisolaris‚Äô system were so close together that this would cause other alien species to discover the solar system as well. The reason why discovery was so scary was because this series ascribes to the ‚ÄúDark Forest‚Äù explanation as to why alien civilizations were so hard to find: that all the surviving civilizations were very technologically advanced groups who distrusted every other civilization by default and operated under a ‚Äúshoot on sight‚Äù protocol so broadcasting one‚Äôs location would get them immediately annihilated. In the case of Earth, this broadcast system was under control of a single individual. This, of course, was an immense responsibility since they were in control of the fate of two civilizations. So, in picking who that individual would be, one would have to make sure that it would be a person who would not activate the signal needlessly, but also give the impression that they would activate the signal when being attacked.</p> <p>This is a very similar issue to what the US had faced during the Cold War. Whenever I watch documentaries or listen to podcasts on the subject, they always talk about how there was so much research being done on this MAD-related game theory problem. For most of my life prior, I always thought that this was really silly given that my impression was that game theory was one of those simple 2x2 games. In retrospect now, I realize that to truly model the complexity of what is going on and include more nuances specific to the situation, you have to consider the exact mechanisms by which a MAD situation would be activated. Questions such as: who exactly has control of the launch, are they likely to retaliate even if they already know they are doomed, are there multiple people involved in the launching of nuclear weapons, how do you maximize the perception of one‚Äôs threat against their opponent without sacrificing other things? All these are questions that can be incorporated into a model that make the question a bit more interesting than one of those ‚Äú2x2 Find the Nash Equilibria‚Äù games.</p> <p>I‚Äôll detail one such model soon, but just for some context we can make to the archetypical 2x2 we see in high school Econ classes (note: that most of these changes are taken as part of a standard model in game theory in the literature, I‚Äôm not too read up on it so I may be missing a few key components):</p> <ul> <li>Tack on some functional structure for the probabilities that both the first and second strike of MAD are activated.</li> <li>Introduce multiple actions (with complete destruction being minus infinity utility). One can even make it an action that lies on some continuous domain instead of discrete choices.</li> <li>For games with sequential actions, we can represent the problem as nested games with each action taken further filtering the state spacetakes.</li> </ul> <p>With all that in mind, let‚Äôs try to construct a model for a Cold War-type situation between two world powers.</p> <iframe src="/assets/pdf/modeling-MAD.pdf" width="100%" height="1000px"></iframe>]]></content><author><name></name></author><category term="econ-thoughts"/><summary type="html"><![CDATA[Note, Some spoilers for the Remembrance of Earth's Past series]]></summary></entry><entry><title type="html">first food post pt. 2</title><link href="https://pranay-gundam.github.io/blog/2024/first-food-post-pt2/" rel="alternate" type="text/html" title="first food post pt. 2"/><published>2024-06-11T19:12:00+00:00</published><updated>2024-06-11T19:12:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/first-food-post-pt2</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/first-food-post-pt2/"><![CDATA[<p>I‚Äôm still cooking up another game theory-related post that will take a bit more time to finish (and so here is another Pittsburgh related food post). The last post covered only some of the neighborhoods in Pittsburgh, so here is the other batch of places that the typical CMU student only goes to sometimes.</p> <ul> <li><strong>Strip District</strong>: This neighborhood is well known for the food scene and the grocery stores. When I lived in North Oakland, I would occasionally walk here (which, in retrospect, was a very sketchy path). I used to go to the Strip District a bit during freshman year since this is where the Red Cross office in Pittsburgh. <ul> <li><em>Restaurant</em>: Coop de Ville (although I have not bought food from this place in person) is my absolute favorite takeout fried chicken place. I‚Äôve gotten GrubHub deliveries from there many times.</li> <li><em>Coffee</em>: De Fer Coffee and Tea happens to be my favorite coffee shop to work at in Pittsburgh just because of the vibe and the ability to take a nice walk in a cool area afterward.</li> <li><em>Misc</em>: Klavon‚Äôs, which unfortunately may not be open anymore, is my favorite ice cream parlor in Pittsburgh. I happen to be a fan of sundaes and Klavon‚Äôs is miles above the competition. Also, Macaroni Company is a cool grocery store.</li> </ul> </li> <li><strong>Downtown</strong>: I rarely went downtown sophomore and junior year (because of the pandemic) and so I didn‚Äôt have as much exposure to this area of Pittsburgh as I did with many of the others. One factor that did help me get more familiar with the area was that I interned at PNC the summer before my senior year, which, in addition to being able to go out for lunch, introduced me to a lot of people who also had their lists of Pittsburgh favorites. <ul> <li><em>Coffee</em>: I never managed to go to Gasoline Street Coffee Company until after I had graduated, but it has a nice vibe (they have a chess board) and has pretty good coffee.</li> <li><em>Lunch Places</em>: Arrepittas has a filling combo platter that would always satisfy my craving for Latin American food. Sree‚Äôs Foods, on the other hand, was one of the few Indian places I enjoyed in Pittsburgh. It was started by this couple from Hyderabad and I feel like they would give me a little extra food when I spoke in Telugu.</li> </ul> </li> <li><strong>Lawrenceville</strong>: This is a neighborhood that is known for some refined restaurants. I‚Äôve only been here a few times so I can‚Äôt speak to much. <ul> <li><em>Restaurant</em>: Picolo forno is a nice Italian place; can‚Äôt say much more than I enjoyed my experience there. Condado‚Äôs on the other hand is a Pittsburgh classic (known for its fusion tacos) and whenever I get takeout from Condados‚Äôs it‚Äôs always from this specific location.</li> <li><em>Coffee</em>: I have surprisingly been to a handful of coffee shops here but Espresso a Mano stands above the rest.</li> </ul> </li> <li><strong>Southside</strong>: Although there are a few spots that I absolutely adore from this neighborhood I‚Äôve actually only visited in person two-three times. <ul> <li><em>Restaurant</em>: The place I‚Äôve gotten the most takeout from in Pittsburgh is Cilantro and Ajo (I don‚Äôt even remember how many times now). The plantains side dish is by far the best plantains I have ever eaten and their cilantro crema is also absolutely amazing.</li> <li><em>Coffee</em>: Delanie‚Äôs Coffee is my pick for the Southside. Not going to lie this is the only coffee place I have gotten coffee from in Southside but it was still pretty decent.</li> </ul> </li> <li><strong>Northside</strong>: Most people don‚Äôt even know the name of this neighborhood other than the fact that it‚Äôs home to The Mattress Factory. I can‚Äôt say I‚Äôm much better to be honest though since this is the neighborhood that I‚Äôve been to the least (although I did know the name). <ul> <li><em>Restaurant/Coffee</em>: 40 North at Alphabet City is the only place I‚Äôve been that I feel is worth putting on this list. There‚Äôs an attached bookshop, and bookshop food combined places are always pretty cool.</li> </ul> </li> <li><strong>Bloomfield</strong>: This neighborhood in my opinion is a weird in between going places neighborhood and so I‚Äôve grouped an interesting swath of area into this place. <ul> <li><em>Restaurant</em>: The first time I went to Apteka I had an amazing time. The second time I will say was not nearly as good of a time as the first and so I‚Äôm conflicted since I came out of the place the first time thinking that it was the best restaurant in Pittsburgh and the second time thinking it was subpar. Regardless it‚Äôs a place that has to be mentioned.</li> <li><em>Coffee</em>: Ineffable Ca Phe is a Vietnamese place that, in addition to coffee, also sells Bahn Mi‚Äôs. It also has a lot of space and quite a few outlets so nice place to camp out to get some work done.</li> </ul> </li> <li><strong>Other mentions</strong>: Wheelfish is the best barbeque place I have been to in Pittsburgh (although it is in some suburban neighborhood that requires a car to get to). The Exchange is actually on the CMU campus and one of the places I think 90% of CMU students can agree upon as being good.</li> </ul> <p>So that‚Äôs my big list of places I wanted to write down somewhere and share. I will also reiterate my list is from the perspective of a college student who is on a budget 99% of the time. I know for a fact that there are some places (especially Downtown, West Southside, and the Strip District) where some better-endowed people tend to go. Regardless I‚Äôm confident that anyone will have a good time at each of the places on my list.</p>]]></content><author><name></name></author><category term="the-pittsburgh-palate"/><summary type="html"><![CDATA[I‚Äôm still cooking up another game theory-related post that will take a bit more time to finish (and so here is another Pittsburgh related food post). The last post covered only some of the neighborhoods in Pittsburgh, so here is the other batch of places that the typical CMU student only goes to sometimes.]]></summary></entry><entry><title type="html">first food post pt. 1</title><link href="https://pranay-gundam.github.io/blog/2024/first-food-post-pt1/" rel="alternate" type="text/html" title="first food post pt. 1"/><published>2024-06-02T13:20:00+00:00</published><updated>2024-06-02T13:20:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/first-food-post-pt1</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/first-food-post-pt1/"><![CDATA[<p>I did promise a few posts back that I would start to post a bit more about food. Cooking and learning about (and eating of course) food are pretty big parts of my life in terms of interests. It developed a lot from being in a family/extended family that values food a lot as well and because of that, I watched a lot of food-related shows during high school/college (which brought about the interest in learning about food from different cultures and the basics of cooking techniques). Even now, although I don‚Äôt watch many shows related to food, there are a lot of YouTubers I watch and some books that I enjoy reading.</p> <p>That all in mind, I happen to consider myself to be quite the connoisseur of restaurants in Pittsburgh (well a connoisseur of all the college student budget-friendly places in Pittsburgh at least); a proxy of how much time I spent in the city and the one summer I spent there basically alone. Pittsburgh is interesting because each of the neighborhoods are clearly culturally distinctive (much like NYC and very much unlike Dallas) but it‚Äôs not as big as other big American cities. The summer I spent in Pittsburgh alone I made it a personal goal to explore a different neighborhood each weekend and I have some recommendations of things to do and places to eat at in each neighborhood that I wanted to share. I will say that there are a few neighborhoods that I didn‚Äôt include but that‚Äôs either most likely because I didn‚Äôt spend that much time there or because there isn‚Äôt anything that comes to mind to take note of.</p> <ul> <li><strong>Shadyside</strong>: I lived here my senior year and had a really nice routine each weekend where I would work/read in a coffee shop and then take a nice walk to get groceries. I still visited this area a lot throughout my four years in Pittsburgh regardless and I‚Äôve basically eaten at every place here. <ul> <li><em>Coffee Shop</em>: Jitters Cafe is a must. This is where I got into my weekend coffee, croissant, and a book/journal routine.</li> <li><em>Bakery</em>: Georgie‚Äôs Corner Cafe is a little on the higher end for a bakery in Pittsburgh for a college student, but it definitely merits multiple visits since each one of their baked goods and breakfast items is so good.</li> <li><em>Restaurant</em>: This is a bit hard to choose from since Walnut St. is such an iconic place for restaurants in Pittsburgh and I‚Äôve been to many of them many times but at the end of the day I have to highlight Caf√© Moulin and Mercurio‚Äôs as my personal favorites.</li> </ul> </li> <li><strong>North Oakland</strong>: I spent basically 2.5 years in North Oakland so this is the place I know the best. That being said, especially senior year once the effects of the pandemic lifted off a bit more, it feels like the turnover of restaurants coming and going is pretty high here. <ul> <li><em>Cafe/Bakery</em>: Sidecar (as it‚Äôs called now, it‚Äôs been through a lot of name changes) is the companion cafe of Butterjoint (a restaurant) which I actually don‚Äôt like as much as I do the cafe.</li> <li><em>Restaurant</em>: In my opinion, this area is really good for college students. Both EGE Mediterranean (the smell coming out of that place as you‚Äôre walking back after a tough day is impossible to resist) and TW Kitchen are really good quality. Most places in this area are small family-owned type places where people remember your face and I liked that a lot.</li> </ul> </li> <li> <p><strong>CMU / Craig St.</strong>: I mostly added this section because I feel like Craig St. needed a section of its own. My friend group liked EatUnique a lot (to be honest, it‚Äôs only financially feasible as a freshman with a lot of flex money). There are a lot of other cool places but I think I‚Äôm doing a disservice if I don‚Äôt put Chipotle on here just because of how many times I went to that Chipotle (even if they do skimp on the chicken)</p> </li> <li> <p><strong>Central Oakland</strong>: I‚Äôm grouping all of the UPitt area into this. I haven‚Äôt been to any cafes here but there are so many restaurants here its hard to keep track. This is a really lesser known place and is unfortunately closed now (its literally in a basement) but I think I have to give an honorable mention to Pie Express. The quality wasn‚Äôt really top notch or close to top notch but they had this $5 personal pizza deal during the pandemic that was amazing. Other than that Milkshake Factory and Roots are two Pittsburgh only places that I‚Äôve visited many a times.</p> </li> <li><strong>Squirrel Hill</strong>: Like Central Oakland, this place is a big CMU hub because a lot of people live here. Squirrel Hill is most iconic for all the Asian restaurants here but also one thing to note is that I‚Äôm grouping in a vast swath of area without making a difference between North, Central/East, and South Squirel Hill. <ul> <li><em>Cafe</em>: For drinks personal favorite is Dobra Tea. Its kind of bougie in its seating area but its a really cool vibe and they take their tea very seriously.</li> <li><em>Bakery</em>: I have never heard anyone at CMU even mention Five Points Bakery which is such a travesty because IMO its miles ahead of all the other bakery competition in Pittsburgh. There are so many unique and well-made items here that you have to visit multiple times.</li> <li><em>Restaurant</em>: I‚Äôm going to have to mention all Cafe 33, Sichuan Gourmet, and Kiin Lao. Kiin Lao and Sichuan Gourtet are the places that got me into liking Thai and Chinese cuisine respectively and are both places I‚Äôve been to quite often.</li> </ul> </li> <li><strong>East Liberty</strong>: I feel like this neighborhood is known primarily among freshman for having a Target and it was the first area I visited just because of this reason. <ul> <li><em>Cafe</em>: I feel like Margaux isn‚Äôt super well known among CMU students but man, do they have really cool desserts.</li> <li><em>Restaurant</em>: Noodlehead to me feels like an iconic Pittsburgh place. I have no idea why and when I ask other CMU students, the sentiment is rarely reciprocated. I think its mostly because it and Choolah were one of the first few places I ate out in Pittsburgh.</li> </ul> </li> </ul> <p>Next week we‚Äôll cover each of the lesser well known places for CMU students.</p> <ul> <li>Strip District</li> <li>Downtown</li> <li>Lawrenceville</li> <li>Southside</li> <li>Northside</li> <li>Bloomfield</li> <li>Waterfront</li> </ul>]]></content><author><name></name></author><category term="the-pittsburgh-palate"/><summary type="html"><![CDATA[I did promise a few posts back that I would start to post a bit more about food. Cooking and learning about (and eating of course) food are pretty big parts of my life in terms of interests. It developed a lot from being in a family/extended family that values food a lot as well and because of that, I watched a lot of food-related shows during high school/college (which brought about the interest in learning about food from different cultures and the basics of cooking techniques). Even now, although I don‚Äôt watch many shows related to food, there are a lot of YouTubers I watch and some books that I enjoy reading.]]></summary></entry><entry><title type="html">Key &amp;amp; Peele teacher draft in real life and the benefits of socio-political gridlock</title><link href="https://pranay-gundam.github.io/blog/2024/KeyPeele-teacher-draft/" rel="alternate" type="text/html" title="Key &amp;amp; Peele teacher draft in real life and the benefits of socio-political gridlock"/><published>2024-05-25T11:28:00+00:00</published><updated>2024-05-25T11:28:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/KeyPeele-teacher-draft</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/KeyPeele-teacher-draft/"><![CDATA[<p>Back in high school, I watched a lot of Key and Peele. One of my favorite skits was ‚ÄúIf We Treated Teachers Like Pro Athletes‚Äù (the video below).</p> <div style="text-align: center;"> <iframe width="560" height="315" src="https://www.youtube.com/embed/aYOg8EON29Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </div> <p>Even though this is a joke, this seems to me like a low-key intriguing idea that seems unexplored. In theory, since public schools are all government-controlled, we already have a big central organization that regulates the hiring and rules of the ‚Äúleague‚Äù (public elementary and secondary education).</p> <p>The hiring process for teachers in public schools is similar to that of most industries; applicants search for their positions and submit applications for those spots. Drafts on the other hand are incredibly different. The choice is taken out of the hands of the applicant (the teachers in this case or the players in the case of sports drafts) for the most part - other than simply refusing to cooperate or expressing interest in a specific hirer beforehand - and the decision making is put into the hands of the hirers. Schools still have the choice in the current system to hire who they want, but they cannot control who applies for the positions that need filling. A draft system would enable schools to target specific individuals in particular growth areas. As a summary, the effects of implementing a draft would be</p> <ul> <li>More equity across schools in teaching quality</li> <li>Ability to enhance particular areas in need of improvement with targeted bids</li> <li>Shift of social/cultural perception of teachers</li> </ul> <p>There is no free lunch, and I also thought of a couple of costs to this draft model:</p> <ul> <li>Good teachers can only do so much to help the quality of underfunded schools</li> <li>Teachers do not get as much agency to act according to their preferences</li> <li>More money is required to compensate teachers appropriately</li> </ul> <p>I wanted to be a bit more quantitative and build out some sort of comparative model where I look at equilibrium in a free hiring model and equilibrium under a draft market model of how much it would cost schools, but to be honest, I simply don‚Äôt have the time or mental capacity for that this weekend.</p> <p>All this speaks to a larger movement to fix the education system that calls for putting more social value in the teaching profession to attract more good teachers. Fixes related to calls for systemic changes in societal values, though easy in practice, are quite difficult to bring about. Each of the social niches is so entrenched in its own culture that a large, all-encompassing social movement is hard to come by and requires a monumental force of social engineering that causes such as fixing the education system - although quite agreed upon that it is an issue - currently don‚Äôt have the right powerful people backing it to bring about concrete change.</p> <p>Speaking of powerful people and politics, I wanted to take a right turn and talk about something that occurred to me while reading Ken Liu‚Äôs The Perfect Match (the more of his short stories I read, the more I realized shows like Black Mirror and Love, Death, and Robots take inspiration from and even use in the case of Good Hunting).</p> <p>It is quite difficult to watch the news or even just live your normal life in the US and not become frustrated with the fact that the sociopolitical views of various groups in the US are so antagonistically polarized. It‚Äôs an emotion that I periodically feel and a sentiment echoed across many of my peers. Recently, however, after reading Ken Liu‚Äôs The Perfect Match, I‚Äôve thought about the issue differently.</p> <p>To summarize the book, it‚Äôs a typical dystopian story of a company that grows so large that they imbue themselves into every part of your life and monitor you so much that they have stored a data version of yourself. Even though I‚Äôve consumed a lot of media like this, this time I was especially reflective about the reality of this situation.</p> <p>Would something that crazy ever be able to happen in real life? Sure, there are small signs of privacy concerns amongst all the tech giants, but for some reason, I just had this underlying belief that something like that would not happen in real life.</p> <p>I think of the public hearings against Zuckerberg and TikTok‚Äôs CEO Shou Zi Chew. It was clear how distrustful some politicians were about technology and how many others echoed the same concern.</p> <p>It hit me then that for a company to grow that out of control feels like it requires uniform support of it, and the socio-political divide of today makes it such that even if one side were to provide staunch support, the other side would be in staunch opposition. Even on both sides, we have so much entertainment showing how things can spiral out of control that I can now sit here typing this out without much worry that these scenarios will come to be.</p> <p>I‚Äôve always abstractly understood the need for diversity of thoughts and opinions, but I‚Äôve always felt like this leads to gridlock and halts progress. It‚Äôs only now that I‚Äôm able to appreciate a concrete example of a substantial positive reason for moving slowly amongst all the cons.</p>]]></content><author><name></name></author><category term="econ-thoughts"/><summary type="html"><![CDATA[Back in high school, I watched a lot of Key and Peele. One of my favorite skits was ‚ÄúIf We Treated Teachers Like Pro Athletes‚Äù (the video below).]]></summary></entry><entry><title type="html">Making packages, OLGs (again?), and Time Averaging Taxation Paper</title><link href="https://pranay-gundam.github.io/blog/2024/making-packages/" rel="alternate" type="text/html" title="Making packages, OLGs (again?), and Time Averaging Taxation Paper"/><published>2024-05-19T16:32:00+00:00</published><updated>2024-05-19T16:32:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/making-packages</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/making-packages/"><![CDATA[<p>Taking CS courses at CMU (especially 15-112) ingrained in me a few principles of OOP that are very relevant when it comes to building packages. While they may seem like very boring and redundant rules at times (such as using getter functions to get information from an object as opposed to directly accessing their attributes), there are obvious long-term benefits of following these practices. I cringe internally whenever I encounter something that goes against those practices (probably a subconscious response as a result of losing many homework points back in the day). I‚Äôve realized more and more how hard it is to uphold that standard in the workforce, especially under time constraints or due to laziness in debugging, but also how much going against that standard deeply demotivates me. I‚Äôve taken up a new commitment to adhere to what I consider to be satisfying coding no matter how long it takes.</p> <p>Along those lines, however, I wanted to reflect on my style of taking on projects. I pride myself on being creative enough to think about new projects, but I have a tendency to get caught up in the initial process of ideation. In turn a lot of the projects fall to the wayside because I‚Äôm not slowing down. It feels like there is no time to just commit to one thing and work through all the grueling ‚Äúun-fun‚Äù parts because before I can do that the next fun idea comes to mind and it feels more satisfying to think about that than it is to endure the other parts from before. This is a problem I have been pretty conscious about within the last year especially and I have made quite a bit of progress on it too (some of the problem is also due to a desire to reach some perfect point with all the projects I take on). It is also something that I want to focus on in the upcoming months before I have to shift focus towards PhD apps. I‚Äôve made some action items to stay true to it (this blog is related to quite a few of them) and I‚Äôll be sure to update the blog with my progress throughout the summer as well.</p> <p>Now, we can talk about some stuff I have going on and also some other exciting things that I‚Äôve done recently. Regarding the relevancy of building packages, now that my classes at NYU are over I have a bit more time to delve into all the projects and ideas that I‚Äôve kept on the back burner for so long. A lot of these - like I‚Äôve alluded to before - are related to building packages or just writing some code around different econ concepts that I‚Äôve been introduced to since starting at the Fed such as structural spacial models or what I intend on working on first, OLGs and Job Searching. These two classes of models were the main points of discussion in Macro I at NYU and I find that often I grasp onto¬† the material when I am able to translate the theory into code. I don‚Äôt want to spend incredible amounts of time on this, so the plan is to create a package-like environment, creating arbitrary models of both types and some supporting analysis code that produces some useful insights. I‚Äôm talking high level right now because I still need to pin down the specifics but I have begun coding the OLGs package and have already encountered an interesting problem.</p> <p>Basically, I want my codebase to work with OLG models that don‚Äôt have obvious mathematical solutions. I don‚Äôt want it to be a calculator that just spits out the solutions to problems I already know how to solve; in this effort to make it more generalizable I‚Äôve come upon a unique problem that comes up when trying to stay true to this environment where the individual agents are interacting with each other, that is, I need to make a mechanism or routine in the code by which agents undergo this interaction which is also mathematically equivalent to the cases I already know how to solve analytically. My initial reaction to this was to consider the setup of a simple OLG model with only households who want to trade consumption bonds (stage contingent or not, it doesn‚Äôt really matter for the sake of this discussion). In this case, agents who want to buy consumption bonds make a bid (the highest price they are willing to buy at) and agents who want to sell consumption bonds make an ask (the lowest price they are willing to sell at). From this point, there are several paradigms we can adopt to do the matching, which is also a feature we can embed into the codebase as well that users can choose. Before I get into a few of the matching algorithms, just to establish some language to speak about this, say that there are n many agents, bids \(\{x_1, x_2, ..., x_k\}\), and asks \(\{y_1, y_2, ..., y_j\}\). A match between any bid x and ask y is only possible when y &lt; x, aka when the highest price the buyer is willing to buy at is higher than the lowest price the seller is willing to sell at. Here are a few methods that I thought of, there are pros and cons of each method that I‚Äôve briefly thought about but some market design people would probably know a lot more than me. Keep in mind, when beliefs about the state space probabilities are homogenous amongst all agents and/or bond prices are not state contingent all these algorithms should yield the same result since everyone believes the prices of bonds to be the same.</p> <p>Most ‚ÄúConsumer Surplus‚Äù: Ultimately we still have to make decisions here about matches between individuals where the bid-ask spread does not perfectly align. Do we defer to the seller, to the buyer, to some other convex combination of both of their offers? In any case, once we decide on a paradigm for deciding the ultimate price we can define consumer surplus as the sum of the differences xi-pi over all matches made indexed by $i$, where pi is the price as a function of some \(f(x_i,y_i)\).¬† Now maximizing consumer surplus is a matter of reconciling this function f with some matching algo. For example, if the function just deferred to choosing the ask price then it would be optimal to match the highest bids with the lowest asks (at least in working out a few examples that‚Äôs what I can tell).</p> <ul> <li> <p><strong>Most ‚ÄúProducer Surplus‚Äù</strong>: The same as above but we look at the maximization problem from the seller‚Äôs perspective.</p> </li> <li><strong>Lottery</strong>: ¬†A lottery system is simple; at its core, it just is a random matching between any possible bid-ask. That being said, there are multiple ways to enact this procedure in practice. <ul> <li>We can index each of the buyers and sellers and then uniformly randomly choose one from each group and make the match if their offers are possible.</li> <li>I can imagine this method would create a bit more deadweight loss than others we have already described because there might be more people who don‚Äôt end up matching.</li> </ul> </li> <li><strong>Fixed Market Price</strong>: One other method is having one function that takes in all the bids and asks (\(f(x_1,...,x_k,y_1,...,y_j)\)) and spits out one price. Then everyone pays for the bond at that price.</li> </ul> <p>Ultimately, I think this translation of the theory to implementation in practice speaks to the complications in how we implement the theory in the real world and how we need to pull from multiple disciplines (both vanilla macro and market design in this case) to bring a model to face the real world.</p> <p>Finally in the theme of stuff that Sargent/Ljungqvist have taught me, three weeks back I went to the Carnegie-Rochester-NYU Conference on Public Policy (a few CMU professors that I‚Äôm close with also showed up which let me say it was an interesting experience going to a conference with past professors, the first time that I have been on the same side of the lecture hall as them) and Ljungqvist was presenting a paper by him Sargent, Holter, and Stepanchuk. Both the paper and Ljungqvist‚Äôs presentation were wholly inspirational to me: it gave me a clear picture of what the ideal paper that I want write is like and where I want to get in terms of my presentation of my work. It would be this macro paper where I motivate it with several key quotes/papers in the literature and then apply this new framework to a pervasive problem in society like taxes or social security - as the paper in question above did. Presentation-wise you could really tell the difference between someone as experienced and enigmatic about what they had created like Ljungqvist vs. some of the other younger economists earlier in their careers.</p> <p>Anyways, I forgot to mention this last week but now that I don‚Äôt have any more classes posts will be weekly; it may not be an in depth quantitative look into some topic because those take a while to work out but I will talk about something (a few rants about food coming up as well).</p>]]></content><author><name></name></author><category term="econ-thoughts"/><summary type="html"><![CDATA[Taking CS courses at CMU (especially 15-112) ingrained in me a few principles of OOP that are very relevant when it comes to building packages. While they may seem like very boring and redundant rules at times (such as using getter functions to get information from an object as opposed to directly accessing their attributes), there are obvious long-term benefits of following these practices. I cringe internally whenever I encounter something that goes against those practices (probably a subconscious response as a result of losing many homework points back in the day). I‚Äôve realized more and more how hard it is to uphold that standard in the workforce, especially under time constraints or due to laziness in debugging, but also how much going against that standard deeply demotivates me. I‚Äôve taken up a new commitment to adhere to what I consider to be satisfying coding no matter how long it takes.]]></summary></entry><entry><title type="html">physics? (intercepting moving bodies in space)</title><link href="https://pranay-gundam.github.io/blog/2024/intercepting-moving-bodies-in-space/" rel="alternate" type="text/html" title="physics? (intercepting moving bodies in space)"/><published>2024-05-12T21:04:00+00:00</published><updated>2024-05-12T21:04:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/intercepting-moving-bodies-in-space</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/intercepting-moving-bodies-in-space/"><![CDATA[<p>I find the cross between Physics and Finance/Economics pretty interesting. There are some statistical methods that are used across both fields and some other stuff as well that I probably am not aware of, but what I find really intriguing is the cross migration of those in the respective fields. The beginnings of quantitative finance happened with a bunch of physics people going into finance. I have had profs who started out in physics and ended up in econ, and myself (and even also a Fed friend as well), the first academic field that I found interesting was physics (specifically the type of stuff you see in books like ‚ÄúThe Universe in a Nutshell‚Äù by Stephen Hawking). I think it is pretty rare, however, for someone to start in econ/finance and end up in physics (probably in large part due to the money prospects in econ/finance and the extreme difficulty in making a mark in physics). Regardless, from time to time I get really interested in physics questions and now find myself with the math tools to be able to ask and answer very basic questions (and also for some reason, probably just because of my math training at CMU, find it so much easier to visualize and put into math the interactions that I am curious about). The attached document is regarding a question that I have thought about a lot and is something that I think a lot of people take for granted but is actually a lot more nuanced than one would think.</p> <p>Before you get to the pdf though, I did want to talk about something in research and general projects across all academic fields. That is the work and bypassing of obstacles that don‚Äôt show up in the final product but are often times the most satisfying problem-solving and time expense during a project. I experienced this while writing my undergrad senior thesis as well, but there are often times so many roadblocks that require so much clever thinking, whether it is finding the best way to write your utility function or discover some neat math trick that lets you solve for equilibrium conditions. People will see the end product but not everything that came in between and the iterative steps of clever thinking. On one hand, it‚Äôs kind of sad for the writer, but for the reader, it makes sure that they aren‚Äôt inundated with stuff they need to interpret. I feel like it would be good for academia to find some sort of standard where paper writers/researchers can put their whole thought process down in an organized manner; that would both satisfy my desire to share all those rough moments but also, I think, increase transparency, which seems like something that is needed amidst a few scandals in faking data that happened a few years back in the econ community.</p> <p>Finally, I also wanted to talk about one specific detail that seems to be the case with a lot of the problems/models of real-world interactions I build: the level of abstraction from reality that I should keep it at. In my head, I know there‚Äôs some sort of a tradeoff between adding yet another ‚Äúlever‚Äù into a model, but so far, I‚Äôve only tackled that issue with continuing to add levers until I get tired and then try to be satisfied with that end product, and I‚Äôm not sure if there‚Äôs a more systematic way of figuring that out. At what point do we stop trying to chase reality, and do we continue to chase it even if it is actually feasible in the first place.</p> <iframe src="/assets/pdf/Intercepting%20Moving%20Bodies%20in%20Space.pdf" width="100%" height="1000px"></iframe>]]></content><author><name></name></author><category term="miscellaneous-math-fun"/><summary type="html"><![CDATA[I find the cross between Physics and Finance/Economics pretty interesting. There are some statistical methods that are used across both fields and some other stuff as well that I probably am not aware of, but what I find really intriguing is the cross migration of those in the respective fields. The beginnings of quantitative finance happened with a bunch of physics people going into finance. I have had profs who started out in physics and ended up in econ, and myself (and even also a Fed friend as well), the first academic field that I found interesting was physics (specifically the type of stuff you see in books like ‚ÄúThe Universe in a Nutshell‚Äù by Stephen Hawking). I think it is pretty rare, however, for someone to start in econ/finance and end up in physics (probably in large part due to the money prospects in econ/finance and the extreme difficulty in making a mark in physics). Regardless, from time to time I get really interested in physics questions and now find myself with the math tools to be able to ask and answer very basic questions (and also for some reason, probably just because of my math training at CMU, find it so much easier to visualize and put into math the interactions that I am curious about). The attached document is regarding a question that I have thought about a lot and is something that I think a lot of people take for granted but is actually a lot more nuanced than one would think.]]></summary></entry><entry><title type="html">reflections on macro I and monkeying around with OLGs</title><link href="https://pranay-gundam.github.io/blog/2024/reflections-on-macro/" rel="alternate" type="text/html" title="reflections on macro I and monkeying around with OLGs"/><published>2024-02-03T13:28:00+00:00</published><updated>2024-02-03T13:28:00+00:00</updated><id>https://pranay-gundam.github.io/blog/2024/reflections-on-macro</id><content type="html" xml:base="https://pranay-gundam.github.io/blog/2024/reflections-on-macro/"><![CDATA[<p>(Note: All of the text of this post was written on December 25th, 2023 while the attached pdf has been edited recently)</p> <p>I just finished a Macro Theory I at NYU with Sargent and Ljungqvist. Thankfully I ended up doing well but even more so than that I realized that I have a lot of interest in Macro. Maybe it was the different nature of taking only one class ‚Äî which allowed me to focus on understanding only one subject thoroughly as opposed to five or six at the same time although I will say that working a job while taking a class is quite difficult ‚Äî but being immersed in so much econ from class to all the work and seminars at the Fed was a different and enjoyable experience in terms of understanding and getting appreciation of the subject.</p> <p>I found myself naturally thinking about extensions of problems we discussed or how equilibriums would changed if we laxed certain assumptions (‚Äúextra thinking‚Äù that I would not do if I was in a class at CMU just struggling to keep up with all the course work) and having the time to actually work out examples myself as well. Very refreshing compared to the four year grind. The two topics of discussion that I have become intrigued with and will work on now before I have to focus on grad apps are structural modeling and just working out a few questions I had on OLG models and how they build out to the more involved macro models used on the frontier. I think I would probably be able to answer my questions with a few google searches leading to a handful of papers to read but it feels like a good exercise to put pen to paper and work it out myself.</p> <p>On that end I‚Äôve attached some of the work that I wanted to look into after the class ended on OLGs (and a few of the other blog posts later will be on some of the structural toy models that I want to have in hand going into grad school).</p> <p>In other news, I will be taking Analysis II again at NYU this spring semester (and after that probably won‚Äôt take any more classes to focus on apps and other personal projects, although who knows may do Macro II next spring if they offer it) which I have heard is not as bad as analysis at CMU so we shall see how that goes in a few weeks.</p> <iframe src="/assets/pdf/OLG-Monkey.pdf" width="100%" height="1000px"></iframe>]]></content><author><name></name></author><category term="econ-thoughts"/><category term="personal-updates"/><summary type="html"><![CDATA[(All of the text of this post was written on December 25th, 2023 while the attached pdf has been edited recently)]]></summary></entry></feed>